{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rEcpdtrEH74f",
        "3fKjDeRiK46Q"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Q1. Seq2seq 모델 구현을 통해 간단한 챗봇을 구현해봅시다!\n",
        "\n",
        "**하단의 패키지를 모두 실행해주세요!**\n"
      ],
      "metadata": {
        "id": "rEcpdtrEH74f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mjtCPrSG-QS"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from keras import Input, Model\n",
        "from keras.layers import Embedding, LSTM, Dropout, Dense\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "MVHpEVFi2PeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**데이터를 불러옵시다**"
      ],
      "metadata": {
        "id": "mNpQIgbu2Lhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/dialogs.txt',sep='\\t',names=['question','answer'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "QeoqnQW5zcUc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "42e21532-0935-4284-a7ce-c6c59c58b205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              question  \\\n",
              "0               hi, how are you doing?   \n",
              "1        i'm fine. how about yourself?   \n",
              "2  i'm pretty good. thanks for asking.   \n",
              "3    no problem. so how have you been?   \n",
              "4     i've been great. what about you?   \n",
              "\n",
              "                                     answer  \n",
              "0             i'm fine. how about yourself?  \n",
              "1       i'm pretty good. thanks for asking.  \n",
              "2         no problem. so how have you been?  \n",
              "3          i've been great. what about you?  \n",
              "4  i've been good. i'm in school right now.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f2b287f-a718-43f9-84a0-180837ea7bf8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi, how are you doing?</td>\n",
              "      <td>i'm fine. how about yourself?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i'm fine. how about yourself?</td>\n",
              "      <td>i'm pretty good. thanks for asking.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i'm pretty good. thanks for asking.</td>\n",
              "      <td>no problem. so how have you been?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>no problem. so how have you been?</td>\n",
              "      <td>i've been great. what about you?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i've been great. what about you?</td>\n",
              "      <td>i've been good. i'm in school right now.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f2b287f-a718-43f9-84a0-180837ea7bf8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5f2b287f-a718-43f9-84a0-180837ea7bf8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5f2b287f-a718-43f9-84a0-180837ea7bf8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-31c3029f-846d-4be4-803b-956b649c8a53\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-31c3029f-846d-4be4-803b-956b649c8a53')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-31c3029f-846d-4be4-803b-956b649c8a53 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "J9pF8Syy2UMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.데이터의 각 컬럼들을 .values를 이용해 다음의 변수에 저장해주세요. (1점)**"
      ],
      "metadata": {
        "id": "7KFrp_lA2UVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_q =df['question'].values\n",
        "data_a =df['answer'].values"
      ],
      "metadata": {
        "id": "Lpxrpmm1IuxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T32W7-bFairr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "1mmXFzNZ2foQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.텍스트 데이터 전처리를 진행해보겠습니다. 하단의 빈칸을 올바르게 채워주세요 (3점)**"
      ],
      "metadata": {
        "id": "eY3rmzaf2fsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "#정규표현식을 이용해 특수문자 정제\n",
        "def clean_text(sent):\n",
        "    return re.sub(r'[!“”\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~]', '', sent)\n",
        "\n",
        "count_words_ques = [len(clean_text(ques).split()) for ques in data_q]\n",
        "counter_words_ques = Counter(count_words_ques)\n",
        "\n",
        "#단어 수가 15 이하인 문장만 선별\n",
        "sorted_q = []\n",
        "sorted_a = []\n",
        "for i,count in enumerate(count_words_ques):\n",
        "    if count <= 15:\n",
        "        sorted_q.append(data_q[i])\n",
        "        sorted_a.append(data_a[i])"
      ],
      "metadata": {
        "id": "4syiuLJQZAq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#답변 데이터에 대해 문장의 시작, 끝 식별자를 추가합니다.\n",
        "sorted_a = ['<START> '+ answ + ' <END>' for answ in sorted_a]"
      ],
      "metadata": {
        "id": "wHwzubl6bZP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(filters='', lower=False)\n",
        "txt = sorted_q + sorted_a\n",
        "\n",
        "#단어 집합 생성해주세요!\n",
        "tokenizer.fit_on_texts(txt)"
      ],
      "metadata": {
        "id": "sVv15OYifnbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "print(f'Vocabulary size : {VOCAB_SIZE}')"
      ],
      "metadata": {
        "id": "znxVQ9Xtg9Xp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b92b78c-0e6c-4977-e975-f6d2b5a4ac5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size : 4038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "4xeY9wW636lX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.인코더와 디코더를 만들어보겠습니다. 하단의 빈칸을 올바르게 채워주세요(3점)**"
      ],
      "metadata": {
        "id": "iV1ftsFJ36pw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder\n",
        "tokenized_questions = tokenizer.texts_to_sequences(sorted_q)\n",
        "maxlen_questions = 15\n",
        "encoder_inp = pad_sequences(tokenized_questions,\n",
        "                            maxlen=maxlen_questions,\n",
        "                            padding='post')\n",
        "\n",
        "print(encoder_inp.shape)\n",
        "print(sorted_q[0])\n",
        "print(tokenized_questions[0])\n",
        "print(encoder_inp[0])"
      ],
      "metadata": {
        "id": "Trv2JzXwvXNu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f758894-4022-4e4c-cf7c-55ef92ff8103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3713, 15)\n",
            "hi, how are you doing?\n",
            "[1787, 34, 16, 4, 479]\n",
            "[1787   34   16    4  479    0    0    0    0    0    0    0    0    0\n",
            "    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder\n",
        "tokenized_answers =  tokenizer.texts_to_sequences(sorted_a)\n",
        "maxlen_answers = np.max([len(x) for x in tokenized_answers])\n",
        "decoder_inp = pad_sequences(tokenized_answers,\n",
        "                            maxlen=maxlen_answers,\n",
        "                            padding='post')\n",
        "\n",
        "print(decoder_inp.shape)\n",
        "print(sorted_a[0])\n",
        "print(tokenized_answers[0])\n",
        "print(decoder_inp[0])"
      ],
      "metadata": {
        "id": "rK0OpR8qvYUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8011d3e1-8fa1-4f2e-f8cb-026bfbc9ba41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3713, 21)\n",
            "<START> i'm fine. how about yourself? <END>\n",
            "[1, 28, 1016, 34, 33, 825, 2]\n",
            "[   1   28 1016   34   33  825    2    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(tokenized_answers)):\n",
        "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
        "\n",
        "padded_answers = pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding='post')\n",
        "decoder_final_output = to_categorical(padded_answers, VOCAB_SIZE)\n",
        "\n",
        "print(decoder_final_output.shape)\n",
        "print(tokenized_answers[0])\n",
        "print(padded_answers[0])\n",
        "print(decoder_final_output[0])"
      ],
      "metadata": {
        "id": "vjF_X066vm0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2756a7df-5337-4ee9-9843-d8ce5f10c8da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3713, 21, 4038)\n",
            "[28, 1016, 34, 33, 825, 2]\n",
            "[  28 1016   34   33  825    2    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_inputs = Input(shape=(None,))\n",
        "enc_embedding = Embedding(input_dim=VOCAB_SIZE,\n",
        "                           output_dim=200, mask_zero=True)(enc_inputs)\n",
        "_, state_h, state_c = LSTM(200, return_state=True)(enc_embedding)\n",
        "enc_states = [state_h, state_c]\n",
        "\n",
        "dec_inputs = Input(shape=(None,))\n",
        "dec_embedding = Embedding(input_dim=VOCAB_SIZE,\n",
        "                          output_dim=200, mask_zero=True)(dec_inputs)\n",
        "dec_lstm = LSTM(200, return_state=True, return_sequences=True)\n",
        "\n",
        "dec_outputs, _, _ = dec_lstm(dec_embedding, initial_state=enc_states)\n",
        "dec_dense = Dense(VOCAB_SIZE, activation='softmax')\n",
        "output = dec_dense(dec_outputs)"
      ],
      "metadata": {
        "id": "T6mXeTW9vqo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "Q9sJgnXk4PU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.모델 학습을 진행해봅시다 (2점)**"
      ],
      "metadata": {
        "id": "OQX9ZZHF4QCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([enc_inputs, dec_inputs], output)\n",
        "model.compile(optimizer=RMSprop(), loss='categorical_crossentropy')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "3C1BHhwpvtAs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92aa14f3-9601-4b62-8cf3-23f1a3ecc680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, None, 200)            807600    ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, None, 200)            807600    ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 [(None, 200),                320800    ['embedding[0][0]']           \n",
            "                              (None, 200),                                                        \n",
            "                              (None, 200)]                                                        \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, None, 200),          320800    ['embedding_1[0][0]',         \n",
            "                              (None, 200),                           'lstm[0][1]',                \n",
            "                              (None, 200)]                           'lstm[0][2]']                \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, None, 4038)           811638    ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3068438 (11.71 MB)\n",
            "Trainable params: 3068438 (11.71 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#에포크와 배치크기를 자유롭게 지정해주세요! 에포크는 클 수록 결과가 좋습니다\n",
        "model.fit([encoder_inp, decoder_inp],\n",
        "           decoder_final_output,\n",
        "           batch_size=64,\n",
        "           epochs=1)"
      ],
      "metadata": {
        "id": "iv_3R-t5wCct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23eedc88-8cef-40c8-a8ac-e19cda3e1d33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59/59 [==============================] - 34s 376ms/step - loss: 6.6597\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bf2933c7d60>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#그대로 실행시켜주세요!\n",
        "def make_inference_models():\n",
        "    dec_state_input_h = Input(shape=(200,))\n",
        "    dec_state_input_c = Input(shape=(200,))\n",
        "    dec_states_inputs = [dec_state_input_h, dec_state_input_c]\n",
        "    dec_outputs, state_h, state_c = dec_lstm(dec_embedding,\n",
        "                                            initial_state=dec_states_inputs)\n",
        "    dec_states = [state_h, state_c]\n",
        "    dec_outputs = dec_dense(dec_outputs)\n",
        "    dec_model = Model(\n",
        "        inputs=[dec_inputs] + dec_states_inputs,\n",
        "        outputs = [dec_outputs] + dec_states)\n",
        "    print('Inference decoder:')\n",
        "    dec_model.summary()\n",
        "    print('Inference encoder:')\n",
        "    enc_model = Model(inputs=enc_inputs, outputs=enc_states)\n",
        "    enc_model.summary()\n",
        "    return enc_model, dec_model\n",
        "\n",
        "def str_to_tokens(sentence):\n",
        "    #words = sentence.lower().split()\n",
        "    words = sentence.split()\n",
        "    tokens_list = list()\n",
        "    for current_word in words:\n",
        "        result = tokenizer.word_index.get(current_word)\n",
        "        if result != '':\n",
        "            tokens_list.append(result)\n",
        "    return pad_sequences([tokens_list], maxlen=maxlen_questions,padding='post')\n",
        "\n",
        "enc_model, dec_model = make_inference_models()"
      ],
      "metadata": {
        "id": "7GZG892Sv_2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d9836b8-6076-477d-85fb-a74c0070f58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference decoder:\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, None, 200)            807600    ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)        [(None, 200)]                0         []                            \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 200)]                0         []                            \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, None, 200),          320800    ['embedding_1[0][0]',         \n",
            "                              (None, 200),                           'input_3[0][0]',             \n",
            "                              (None, 200)]                           'input_4[0][0]']             \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, None, 4038)           811638    ['lstm_1[1][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1940038 (7.40 MB)\n",
            "Trainable params: 1940038 (7.40 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Inference encoder:\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 200)         807600    \n",
            "                                                                 \n",
            " lstm (LSTM)                 [(None, 200),             320800    \n",
            "                              (None, 200),                       \n",
            "                              (None, 200)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1128400 (4.30 MB)\n",
            "Trainable params: 1128400 (4.30 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#역시 그대로 실행해주세요!\n",
        "def chatbot():\n",
        "    print('Bot: Hi, good to see you')\n",
        "\n",
        "    while True:\n",
        "        input_question = input('Question: ')\n",
        "\n",
        "        if input_question == 'bye':\n",
        "            print('Bot answer: Have a wonderful day :)')\n",
        "            break\n",
        "        states_values = enc_model.predict(str_to_tokens(input_question))\n",
        "        empty_target_seq = np.zeros((1,1))\n",
        "        empty_target_seq[0,0] = tokenizer.word_index['<START>']\n",
        "        stop_condition = False\n",
        "        decoded_translation = ''\n",
        "        while not stop_condition:\n",
        "            dec_outputs, h, c = dec_model.predict([empty_target_seq]+states_values)\n",
        "            sampled_word_index = np.argmax(dec_outputs[0,-1, :])\n",
        "            sampled_word = None\n",
        "            for word, index in tokenizer.word_index.items():\n",
        "                if sampled_word_index == index:\n",
        "                    if word != '<END>':\n",
        "                        decoded_translation += f'{word} '\n",
        "                    sampled_word = word\n",
        "\n",
        "            if sampled_word == '<END>' or len(decoded_translation.split()) > maxlen_answers:\n",
        "                stop_condition = True\n",
        "            empty_target_seq = np.zeros((1,1))\n",
        "            empty_target_seq[0,0] = sampled_word_index\n",
        "            states_values = [h,c]\n",
        "\n",
        "        print('Bot answer:', decoded_translation, '\\n')"
      ],
      "metadata": {
        "id": "dluCo66YwsIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "UuPAYlDe4c0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.챗봇을 실행시켜 대화를 시도해보세요! (1점)**\n",
        "\n",
        "(단, 영어만 가능합니다)"
      ],
      "metadata": {
        "id": "oFaeQ6sv4c6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot()"
      ],
      "metadata": {
        "id": "-W6HKOMrdtbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fKjDeRiK46Q"
      },
      "source": [
        "# Q2. GRU를 활용해 간단한 챗봇 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NckGwH1lPcbe"
      },
      "source": [
        "간단한 원리를 배우는 느낌이니까 편한하게 실행해주세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJTlamn3V07r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import tqdm\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2PnW5UhPcbk"
      },
      "source": [
        "## 1. 단어 집합을 만들어봅시다. (빈칸을 채워주세요)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUJ6-1JGL4rp"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self):\n",
        "        # SOS 토큰은 0, EOS 토큰은 1이 되게 dictionary를 만들어주세요\n",
        "        self.word2index = {\"SOS\": 0, \"EOS\": 1}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        # 처음 단어 집합의 개수는 2개입니다.\n",
        "        self.n_words = 2\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "def prepareData(questions, answers):\n",
        "    lang = Lang()\n",
        "    pairs = []\n",
        "    for i in range(len(questions)):\n",
        "        lang.addSentence(questions[i])\n",
        "        lang.addSentence(answers[i])\n",
        "        pairs.append([questions[i], answers[i]])\n",
        "    return lang, pairs\n",
        "\n",
        "questions = ['안녕', '넌 누구니', '누구','몇 살이야', '오늘 날씨 어때','오늘 어때' , '몇','날씨','몇 살']\n",
        "answers = ['안녕하세요', '저는 챗봇이에요','챗봇', '저는 2살입니다.', '오늘은 춥습니다.','오늘 좋아','2','추워','2살']\n",
        "lang, pairs = prepareData(questions, answers)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKbGham3Pcbo"
      },
      "source": [
        "## 2. Encoder와 Decoder를 정의해 봅시다. (빈칸을 채워주세요!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJSQHzkDcipk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        # Decoder의 embedding은 output_size를 받습니다.\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        # Linear 레이어의 input_size는 hidden_size입니다.\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvBkdqgFPcby"
      },
      "source": [
        "## 3. 훈련함수를 정의해봅시다. (빈칸을 채워주세요!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ajka5XQd33M"
      },
      "outputs": [],
      "source": [
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "    # 차원을 축소해야할지 늘려야할지 생각하여 알맞은 코드를 적어주세요.\n",
        "    input_tensor = input_tensor.unsqueeze(1)\n",
        "    target_tensor = target_tensor.unsqueeze(1)\n",
        "\n",
        "    # 어떤 부분이 length를 의미하는지 생각하여 알맞은 숫자를 적어주세요!\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "    # decoder의 첫번째 값은 무엇이 들어가는지 생각하여 알맞은 코드를 입력해주세요.\n",
        "    decoder_input = torch.tensor([[SOS_token]])\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    for di in range(target_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        topv, topi = decoder_output.topk(1)\n",
        "        decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        loss += criterion(decoder_output, target_tensor[di])\n",
        "        if decoder_input.item() == EOS_token:\n",
        "            break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofMVY9YMPcb0"
      },
      "source": [
        "## 4. 실제로 훈련을 시켜보고 test를 직접해봅시다. (빈칸을 채워주세요!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRQa_Q_3d4Wd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda5aec6-0e25-4001-f077-6d8bd528e963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [02:06<00:00,  7.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q:  안녕하세요\n",
            "A:  추워\n",
            "Q:  누구\n",
            "A:  챗봇\n",
            "Q:  몇 살\n",
            "A:  2살\n",
            "Q:  날씨 어때\n",
            "A:  오늘은 춥습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 256\n",
        "encoder = Encoder(lang.n_words, hidden_size)\n",
        "decoder = Decoder(hidden_size, lang.n_words)\n",
        "\n",
        "encoder_optimizer = optim.AdamW(encoder.parameters(), lr=0.01)\n",
        "decoder_optimizer = optim.AdamW(decoder.parameters(), lr=0.01)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "for epoch in tqdm.tqdm(range(1000)):\n",
        "    for pair in pairs:\n",
        "        input_tensor = torch.tensor([lang.word2index[word] for word in pair[0].split(' ')]+[EOS_token])\n",
        "        target_tensor = torch.tensor([lang.word2index[word] for word in pair[1].split(' ')]+[EOS_token])\n",
        "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "\n",
        "# 테스트\n",
        "def evaluate(sentence):\n",
        "    # test시 필수적으로 입력해야하는 코드를 생각하여 적어주세요.\n",
        "    with torch.no_grad():\n",
        "        input_tensor = torch.tensor([lang.word2index[word] for word in sentence.split(' ')]+[EOS_token])\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]])\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(input_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words\n",
        "# 실제로 테스트를 재미삼아 해보시기 바랍니다!!\n",
        "for question in ['안녕하세요' ,'누구' ,'몇 살','날씨 어때']:\n",
        "    print('Q: ', question)\n",
        "    print('A: ', ' '.join(evaluate(question)[:-1]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WEUseXRyceqO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}