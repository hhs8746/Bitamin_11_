{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQm8v1zsccwY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available else 'cpu'"
      ],
      "metadata": {
        "id": "faL0-MrAS_aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(10)\n",
        "torch.cuda.manual_seed(10)"
      ],
      "metadata": {
        "id": "Dc6ajLuLRwOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CIFAR10데이터를 train_dataset과 test_dataset으로 torchvision을 통해 불러오시오\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "UarI98xTcsjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a889e3a-2956-43dd-a908-363a55323098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 54546419.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#batch크기를 128로 해서 train_loader을 만드시오 (DataLoader이용)\n",
        "batchsize = 128\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batchsize)"
      ],
      "metadata": {
        "id": "nVgrkjOIg_0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dJyLyyYjhZW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ryg8spZR00Vc"
      },
      "outputs": [],
      "source": [
        "# model을 구성하시오 (class로 해도 좋고 바로 sequential을 이용해도 좋습니다.)\n",
        "#우리의 목표는 cifar10 데이터의 class분류임을 고려해서 모델을 만드시오\n",
        "#flatten을 이용해서 1차원으로 변환하고 linear 3번이상 사용하고 활성화 함수는 ReLU를 사용하시오\n",
        "#hidden layer차원은 128으로 하시오(hidden 차원은 사실 마음대로 하셔도 좋습니다)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6KK9GB63YAy"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(nn.Flatten(),\n",
        "                      nn.Linear(3*32*32,128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 10),\n",
        "                      nn.Softmax())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "OwjYUa_eTckU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tbFueiDHdvz"
      },
      "outputs": [],
      "source": [
        "\n",
        "#learning_rate를 0.005로 해서 Adam optimizer를 정의하시오\n",
        "#손실함수는 cross_entropy를 사용하시오\n",
        "learning_rate = 0.005\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "cross_entropy = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci7hNgG8HOvq",
        "outputId": "27d33f33-b340-4a38-b479-fb49a8242b91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.2312\n",
            "Accuracy: 0.2879\n",
            "Accuracy: 0.2960\n",
            "Accuracy: 0.3010\n",
            "Accuracy: 0.3100\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#epoch는 5로해서 학습진행하고 각 epoch마다 accuracy를 출력하시오\n",
        "num_B = 5\n",
        "loss_vec = np.zeros(num_B)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "for i in range(num_B):\n",
        "  val_vec = []\n",
        "  for j, (data, target) in enumerate(train_loader):\n",
        "    data=data.to(device)\n",
        "    target=target.to(device)\n",
        "    output = model(data)\n",
        "    loss = cross_entropy(output, target)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    predicted = torch.max(output.data,1)\n",
        "    v =((predicted.indices == target).sum()).item()/len(target)\n",
        "    val_vec.append(v)\n",
        "  print (\"Accuracy: {:.4f}\".format(np.array(val_vec).mean()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t6KM2J27_WFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#앞에서 받은 test_dataset을 이용해서 test_loader을 만들고 testset의 (평균)정확도를 출력하시오\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,batchsize)"
      ],
      "metadata": {
        "id": "5e9evbbuMZwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "val_vec=[]\n",
        "for i, (data,target) in enumerate(test_loader):\n",
        "    data=data.to(device)\n",
        "    target=target.to(device)\n",
        "    output=model(data)\n",
        "    predicted = torch.max(output.data,1)\n",
        "    v = ((predicted.indices == target).sum()).item()/len(target)\n",
        "    val_vec.append(v)\n",
        "print (\"Accuracy: {:.4f}\".format(np.array(val_vec).mean()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpZn--hXMQjy",
        "outputId": "d0ad0bca-b86d-4d3a-c61f-57a320037c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.2738\n"
          ]
        }
      ]
    }
  ]
}