{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 문제 1. CNN으로 MNIST 분류해보기"
      ],
      "metadata": {
        "id": "SazvvZQX6mpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 필요한 모듈 가져오기"
      ],
      "metadata": {
        "id": "i47P99fg6-ga"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63FnDYyh1Y_1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.modules.dropout import Dropout2d\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU 혹은 GPU 장치 확인\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "D2g90SUL1gxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.  MNIST 데이터셋 내려받기\n",
        "**문제 1-1** 코드 빈칸을 채워주세요. **(1점)**"
      ],
      "metadata": {
        "id": "y7PMNxlH1apx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor() # 텐서로 변환"
      ],
      "metadata": {
        "id": "ZrE78vvqI4vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = torchvision.datasets.MNIST(\n",
        "    root = './data/MNIST', # 다운로드 경로 지정\n",
        "    train = True, # True를 지정하면 훈련 데이터로 다운로드\n",
        "    download = True,\n",
        "    transform = transform)\n",
        "\n",
        "test_set = torchvision.datasets.MNIST(\n",
        "    root = './data/MNIST',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transform)"
      ],
      "metadata": {
        "id": "VMPuQhWc1jpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 데이터를 데이터로더에 전달\n",
        "\n",
        "**문제 1-2**\n",
        "코드 빈칸을 채워주세요. **(1점)**\n",
        "<br><br>(배치사이즈 = 100)"
      ],
      "metadata": {
        "id": "bTal4nqK1kPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set, batch_size = 100, shuffle = True)\n",
        "test_loader = DataLoader(test_set, batch_size = 100, shuffle = True)"
      ],
      "metadata": {
        "id": "eNs8z6QV1oVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. input_size 확인"
      ],
      "metadata": {
        "id": "w8hL9uFA1n40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples = enumerate(train_set)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "example_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PB6yIHav1xHN",
        "outputId": "43d6279e-bd60-4782-d153-ee8713936e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "P5L6L_YfphBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 합성곱 네트워크 생성\n",
        "\n",
        "**문제 1-3** 코드 빈칸을 채워주세요. **(3점)**"
      ],
      "metadata": {
        "id": "Dm8hZqbQ1xcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(CNN, self).__init__()\n",
        "      # 첫번째층\n",
        "      # 입력이미지 shape (?, 28, 28, 1)\n",
        "      # conv (?, 28, 28, 32)\n",
        "      # pooling (?, 14, 14, 32)\n",
        "\n",
        "      self.layer1 = torch.nn.Sequential(\n",
        "          torch.nn.Conv2d(1, 32, kernel_size =3 , stride=1, padding=1),\n",
        "          nn.BatchNorm2d(32),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "      # 두번째층\n",
        "      # 입력이미지 shape (?, 14, 14, 32)\n",
        "      # conv (?, 14, 14, 64)\n",
        "      # pooling (?, 7, 7, 64)\n",
        "\n",
        "      self.layer2 = torch.nn.Sequential(\n",
        "          torch.nn.Conv2d(32,64, kernel_size =3 , stride=1, padding=1),\n",
        "          nn.BatchNorm2d(64),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "      # 7*7*64 inputs -> 10 Outputs\n",
        "      self.fc1 = torch.nn.Linear(7*7*64, 600, bias = True)\n",
        "      self.drop = nn.Dropout2d(0.25)\n",
        "      self.fc2 = torch.nn.Linear(600, 120, bias = True)\n",
        "      self.fc3 = torch.nn.Linear(120, 10, bias = True)\n",
        "\n",
        "    def forward(self, x):\n",
        "      out = self.layer1(x)\n",
        "      out = self.layer2(out)\n",
        "      out = out.view(out.size(0), -1) # Flatten\n",
        "      out = self.fc1(out)\n",
        "      out = self.drop(out)\n",
        "      out = self.fc2(out)\n",
        "      out = self.fc3(out)\n",
        "      return out\n",
        "\n"
      ],
      "metadata": {
        "id": "iQGhiRZV12gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 합성곱 네트워크를 위한 모델 및 파라미터 정의\n",
        "\n",
        "**문제 1-4** 코드 빈칸을 채워주세요. **(1점)**"
      ],
      "metadata": {
        "id": "-ldKXA_l1241"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "num_epochs = 5"
      ],
      "metadata": {
        "id": "LaHhef2C17DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cqYizphAPDDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델 정의\n",
        "model = CNN().to(device)\n",
        "\n",
        "# 비용 함수와 optimizer 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "print(model) # 모델 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2emyVMBd6Dw2",
        "outputId": "521478e7-1558-4de5-a623-8795e998d197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc1): Linear(in_features=3136, out_features=600, bias=True)\n",
            "  (drop): Dropout2d(p=0.25, inplace=False)\n",
            "  (fc2): Linear(in_features=600, out_features=120, bias=True)\n",
            "  (fc3): Linear(in_features=120, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. 모델 학습 및 성능 평가\n",
        "\n",
        "**문제 1-5** 아래 코드 빈칸을 자유롭게 채워주세요. **(4점)**\n",
        "<br><br> (학습 데이터를 이용하여 모델을 학습시키고, test_set으로 모델 성능을 평가해주세요.)"
      ],
      "metadata": {
        "id": "or2p1IJd17Og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "loss_list = []\n",
        "iteration_list = []\n",
        "accuracy_list = []\n",
        "\n",
        "predictions_list = []\n",
        "labels_list = []\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  for images, labels in train_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    train = Variable(images.view(100,1,28,28))\n",
        "    labels = Variable(labels)\n",
        "\n",
        "    outputs = model(train)\n",
        "    loss = criterion(outputs, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    count += 1\n",
        "\n",
        "    #test\n",
        "    if not (count%50):\n",
        "      total = 0\n",
        "      correct = 0\n",
        "      for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        labels_list.append(labels)\n",
        "        test = Variable(images.view(100,1,28,28))\n",
        "        outputs = model(test)\n",
        "        predictions = torch.max(outputs, 1)[1].to(device)\n",
        "        predictions_list.append(predictions)\n",
        "        correct +=  (predictions == labels).sum()\n",
        "        total += len(labels)\n",
        "\n",
        "      accuracy = correct * 100 / total\n",
        "      loss_list.append(loss.data)\n",
        "      iteration_list.append(count)\n",
        "      accuracy_list.append(accuracy)\n",
        "\n",
        "    if not(count%500):\n",
        "      print(\"Iteration: {}, Loss: {}, Accuracy: {}%\".format(count, loss.data,\n",
        "                                                            accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUaw722l195J",
        "outputId": "37ec225b-d5a2-4620-f0c8-ec43b0a2defa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 500, Loss: 0.0922522246837616, Accuracy: 97.81999969482422%\n",
            "Iteration: 1000, Loss: 0.17655937373638153, Accuracy: 97.6500015258789%\n",
            "Iteration: 1500, Loss: 0.047286368906497955, Accuracy: 98.20999908447266%\n",
            "Iteration: 2000, Loss: 0.015769969671964645, Accuracy: 98.29000091552734%\n",
            "Iteration: 2500, Loss: 0.009886989369988441, Accuracy: 98.69000244140625%\n",
            "Iteration: 3000, Loss: 0.23679059743881226, Accuracy: 98.75%\n",
            "Iteration: 3500, Loss: 0.026725171133875847, Accuracy: 98.13999938964844%\n",
            "Iteration: 4000, Loss: 0.011718673631548882, Accuracy: 98.5999984741211%\n",
            "Iteration: 4500, Loss: 0.023680973798036575, Accuracy: 98.95999908447266%\n",
            "Iteration: 5000, Loss: 0.001206500455737114, Accuracy: 98.41999816894531%\n",
            "Iteration: 5500, Loss: 0.007774607744067907, Accuracy: 98.81999969482422%\n",
            "Iteration: 6000, Loss: 0.1092161163687706, Accuracy: 98.91000366210938%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문제2\n",
        "CIFAR10 데이터 불러오기 (torchvision.datasets)"
      ],
      "metadata": {
        "id": "gRUl-XSTHiHz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zL0YPTT4A6jV",
        "outputId": "5ecf8dab-0e72-4c33-b8b0-ebad77405d34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12895637.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import copy\n",
        "import glob\n",
        "import cv2\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))]\n",
        "    )\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(trainset), len(testset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZUwGSsnTn7y",
        "outputId": "496ab762-0b2a-4a82-d60c-d043cfb8fdf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(trainloader))[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C8PO3q_WxPx",
        "outputId": "87502848-7294-4d09-b916-778e8a325e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전이 학습\n",
        "\n",
        "모델 객체 생성(VGG16 모델 사용)"
      ],
      "metadata": {
        "id": "YdW_SbcSHmxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define VGG model\n",
        "model = models.vgg16(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo32DP4nC-Fz",
        "outputId": "1d157a8f-2c5c-43d8-d0e7-03320f5e33c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:26<00:00, 20.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1. 모델의 가중치를 전부 고정하시오.(1점)"
      ],
      "metadata": {
        "id": "yMPRRvDyH9VZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "id": "r5xGlu2aF7FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2. 모델에서 데이터 분류기(classifier)의 마지막 layer를 CIFAR10 데이터의 분류 클래스 수에 맞게 조정하시오.(1점)"
      ],
      "metadata": {
        "id": "xCKCk_K6IfC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnR6RCGQFDFf",
        "outputId": "bbe990be-b24c-4538-e963-0ad630b82a0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.classifier[6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMskV_8SEpeM",
        "outputId": "d242d412-b1ed-47cf-9198-6637ce02f495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=4096, out_features=1000, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier[6] = nn.Linear(4096, 10)"
      ],
      "metadata": {
        "id": "05S8PRYNC-DL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3. 데이터 분류기(classifier) 층의 가중치 고정을 해제하시오. (1점)"
      ],
      "metadata": {
        "id": "nFwMlMlrKXF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.classifier.parameters():\n",
        "  param.requires_grad = True"
      ],
      "metadata": {
        "id": "5HtJ9_7jF7CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q4. 손실함수 및 optimizer를 정의하시오. (optimizer : Adam사용, lr=0.001) (2점)\n"
      ],
      "metadata": {
        "id": "E66dVBnfOi4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_to_update = []\n",
        "for name,param in model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NSAX00OatC9",
        "outputId": "3e727f41-2b45-4286-b535-cb6acce25ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t classifier.0.weight\n",
            "\t classifier.0.bias\n",
            "\t classifier.3.weight\n",
            "\t classifier.3.bias\n",
            "\t classifier.6.weight\n",
            "\t classifier.6.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(params_to_update,  lr=0.001)"
      ],
      "metadata": {
        "id": "XI6HQ_DWCDa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q5. 모델을 학습하시오. (num_epochs = 10) (3점)\n",
        "\n",
        "(학습시간을 짧게하기 위해 데이터 증강 및 이미지 크기 조정 등을 하지 않았고 이에 따라 성능이 구린게 맞습니다.)(gpu사용 시 약 10분 소요)\n",
        "\n",
        "(매 epoch마다 train_loss와 train_accuracy를 출력할것)\n",
        "\n",
        "(매 epoch마다 모델을 저장할 것)"
      ],
      "metadata": {
        "id": "TonM1kK7Pyrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "train_acc_history = []\n",
        "train_loss_history = []\n",
        "train_best_acc = 0.0\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "    print('-' * 10)\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        model.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "    epoch_loss = running_loss / len(trainloader.dataset)\n",
        "    epoch_acc = running_corrects.double() / len(trainloader.dataset)\n",
        "\n",
        "    print('Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "\n",
        "    if epoch_acc > train_best_acc:\n",
        "        train_best_acc = epoch_acc\n",
        "\n",
        "    train_acc_history.append(epoch_acc.item())\n",
        "    train_loss_history.append(epoch_loss)\n",
        "    os.makedirs(os.path.join('model'), exist_ok=True)\n",
        "    torch.save(model.state_dict(), os.path.join('model/', '{0:0=2d}.pth'.format(epoch)))\n",
        "    print()\n",
        "\n",
        "print('Best Acc: {:4f}'.format(train_best_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-JJeNwOOunw",
        "outputId": "dcdaf88d-ba8a-4e63-aae1-1a21c181c7a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "Loss: 1.5395 Acc: 0.5194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [01:06<10:02, 66.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "Loss: 1.4383 Acc: 0.5438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [01:58<07:42, 57.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "Loss: 1.3816 Acc: 0.5588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [02:53<06:37, 56.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "Loss: 1.3394 Acc: 0.5706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [03:45<05:27, 54.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "Loss: 1.3221 Acc: 0.5766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [04:39<04:33, 54.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "Loss: 1.3130 Acc: 0.5783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [05:31<03:34, 53.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "Loss: 1.2904 Acc: 0.5854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [06:23<02:39, 53.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "Loss: 1.2714 Acc: 0.5968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [07:22<01:50, 55.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "Loss: 1.2460 Acc: 0.6010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [08:15<00:54, 54.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "Loss: 1.2312 Acc: 0.6043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [09:07<00:00, 54.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Acc: 0.604340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q6. 저장했던 10개의 모델을 불러와 테스트 데이터를 평가하시오.(2점)\n",
        "\n",
        "(매 epoch마다 test_accuracy를 출력할 것)\n",
        "\n"
      ],
      "metadata": {
        "id": "I5shgX5lQpd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc_history = []\n",
        "test_best_acc = 0.0\n",
        "\n",
        "saved_models = glob.glob('model/' + '*.pth')\n",
        "saved_models.sort()\n",
        "print('saved_model', saved_models)\n",
        "\n",
        "for model_path in saved_models:\n",
        "    print('Loading model', model_path)\n",
        "\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in testloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs)\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        running_corrects += preds.eq(labels).int().sum()\n",
        "\n",
        "    epoch_acc = running_corrects.double() / len(testloader.dataset)\n",
        "    print('Acc: {:.4f}'.format(epoch_acc))\n",
        "\n",
        "    if epoch_acc > test_best_acc:\n",
        "        test_best_acc = epoch_acc\n",
        "\n",
        "    test_acc_history.append(epoch_acc.item())\n",
        "    print()\n",
        "\n",
        "print('Best Acc: {:4f}'.format(test_best_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duowR7PqMkm5",
        "outputId": "729d7547-7abe-46a9-90d5-b6e362844fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved_model ['model/00.pth', 'model/01.pth', 'model/02.pth', 'model/03.pth', 'model/04.pth', 'model/05.pth', 'model/06.pth', 'model/07.pth', 'model/08.pth', 'model/09.pth']\n",
            "Loading model model/00.pth\n",
            "Acc: 0.6200\n",
            "\n",
            "Loading model model/01.pth\n",
            "Acc: 0.6171\n",
            "\n",
            "Loading model model/02.pth\n",
            "Acc: 0.6376\n",
            "\n",
            "Loading model model/03.pth\n",
            "Acc: 0.6239\n",
            "\n",
            "Loading model model/04.pth\n",
            "Acc: 0.6325\n",
            "\n",
            "Loading model model/05.pth\n",
            "Acc: 0.6375\n",
            "\n",
            "Loading model model/06.pth\n",
            "Acc: 0.6341\n",
            "\n",
            "Loading model model/07.pth\n",
            "Acc: 0.6324\n",
            "\n",
            "Loading model model/08.pth\n",
            "Acc: 0.6528\n",
            "\n",
            "Loading model model/09.pth\n",
            "Acc: 0.6501\n",
            "\n",
            "Best Acc: 0.652800\n"
          ]
        }
      ]
    }
  ]
}